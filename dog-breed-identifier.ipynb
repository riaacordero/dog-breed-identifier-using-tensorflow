{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers.legacy import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    dir= os.getcwd()\n",
    "    path = os.path.join(dir, \"dataset\")\n",
    "    \n",
    "    tr_path = os.path.join(path, \"train/*\")\n",
    "    ts_path = os.path.join(path, \"test/*\")\n",
    "    labels_path = os.path.join(path, \"labels.csv\")\n",
    "\n",
    "    labels_df = pd.read_csv(labels_path)\n",
    "    breed = labels_df[\"breed\"].unique()\n",
    "    print(\"Number of breeds: \", len(breed))\n",
    "\n",
    "    breed2id = { name: i for i, name in enumerate(breed) }\n",
    "\n",
    "    ids = glob(tr_path)\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for image_id in ids:\n",
    "        image_id = image_id.split(\"/\")[-1].split(\".\")[0]\n",
    "        print(image_id)\n",
    "\n",
    "        breed_name = list(labels_df[labels_df.id == image_id][\"breed\"])[0]\n",
    "        print(image_id, breed_name)\n",
    "\n",
    "        breed_index = breed2id[breed_name]\n",
    "        labels.append(breed_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_ts = train_test_split(ids, test_size=0.2, random_state=42)\n",
    "y_tr, y_ts = train_test_split(labels, test_size=0.2, random_state=42)\n",
    "\n",
    "size = 224\n",
    "num_classes = len(breed)\n",
    "lr = 1e-4\n",
    "batch = 8\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model (size, num_classes):\n",
    "    inputs = Input((size, size, 3))\n",
    "    backbone = MobileNetV2(input_tensor=inputs, weights='imagenet', include_top=False)\n",
    "    backbone.trainable = True\n",
    "\n",
    "    x = backbone.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(size, num_classes)\n",
    "model.compile(optimizer=Adam(lr), loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_read(path, size):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (size, size))\n",
    "    img = img/255.0\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(x,y):\n",
    "    x = x.decode()\n",
    "\n",
    "    num_class = 120\n",
    "    size = 224\n",
    "\n",
    "    img = img_read(x, size)\n",
    "    label = [0] * num_class\n",
    "    label[y] = 1\n",
    "    label = np.array(label)\n",
    "    label = label.astype(np.int32)\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    x, y = tf.numpy_function(parse_data, [x, y], [tf.float32, tf.int32])\n",
    "    x.set_shape((size, size, 3))\n",
    "    y.set_shape((num_classes))\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_ds(x, y, batch=8):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    ds = ds.map(tf_parse)\n",
    "    ds = ds.batch(batch)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = tf_ds(x_tr, y_tr, batch=batch)\n",
    "ts_dataset = tf_ds(x_ts, y_ts, batch=batch)\n",
    "\n",
    "for x, y in tr_dataset:\n",
    "    print(x.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids[:1000]\n",
    "labels = labels[:1000]\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"model.h5\", verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "tr_steps = (len(x_tr) // batch) + 1\n",
    "ts_steps = (len(x_ts) // batch) + 1\n",
    "\n",
    "\n",
    "model.fit(tr_dataset, \n",
    "          steps_per_epoch=tr_steps,\n",
    "          validation_steps=ts_steps,\n",
    "          epochs=epochs,\n",
    "          validation_data=ts_dataset,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2breed = {i: name for i, name in enumerate(breed)}\n",
    "\n",
    "model = tf.keras.models.load_model(\"model.h5\")\n",
    "\n",
    "for i, path in tqdm(enumerate(x_ts[:50])):\n",
    "    img = img_read(path,224)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    pred = model.predict(img)[0]\n",
    "\n",
    "    label_index = np.argmax(pred)\n",
    "    breed_name = id2breed[label_index]\n",
    "\n",
    "    orig_breed = id2breed[y_ts[i]]\n",
    "    orig_img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    orig_img = cv2.putText(orig_img, breed_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)\n",
    "    orig_img = cv2.putText(orig_img, orig_breed, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    if not os.path.exists(os.path.join(dir, \"output\")):\n",
    "        os.makedirs(os.path.join(dir, \"output\"))\n",
    "        \n",
    "    cv2.imwrite(os.path.join(dir, \"output\", f\"{i}.jpg\"), orig_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
